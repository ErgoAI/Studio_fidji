/* File:   FloraTokenMaker.flex
**
** Author(s): Miguel Calejo
**
** Contact:   mc@interprolog.com
**
** Copyright (C) Coherent Knowledge Systems, LLC, 2014 - 2016.
** All rights reserved.
**
*/


package com.coherentknowledge.fidji;
import com.declarativa.fiji.*;
import java.io.*;
import java.util.*;
import javax.swing.text.Segment;
import javax.swing.text.BadLocationException;
import org.fife.ui.rsyntaxtextarea.*;
import org.fife.ui.rsyntaxtextarea.modes.*;


/**
 * Scanner for Flora text.
 *
 * This implementation was created using
 * <a href="http://www.jflex.de/">JFlex</a> 1.4.1; however, the generated file
 * was modified for performance.  Memory allocation needs to be almost
 * completely removed to be competitive with the handwritten lexers (subclasses
 * of <code>AbstractTokenMaker</code>), so this class has been modified so that
 * Strings are never allocated (via yytext()), and the scanner never has to
 * worry about refilling its buffer (needlessly copying chars around).
 * We can achieve this because RText always scans exactly 1 line of tokens at a
 * time, and hands the scanner this line as an array of characters (a Segment
 * really).  Since tokens contain pointers to char arrays instead of Strings
 * holding their contents, there is no need for allocating new memory for
 * Strings.<p>
 *
 * The actual algorithm generated for scanning has, of course, not been
 * modified.<p>
 *
 * If you wish to regenerate this file yourself, keep in mind the following:
 * <ul>
 *   <li>The generated <code>FloraTokenMaker.java</code> file will contain
 *       two definitions of both <code>zzRefill</code> and <code>yyreset</code>.
 *       You should hand-delete the second of each definition (the ones
 *       generated by the lexer), as these generated methods modify the input
 *       buffer, which we'll never have to do.</li>
 *   <li>You should also change the declaration/definition of zzBuffer to NOT
 *       be initialized.  This is a needless memory allocation for us since we
 *       will be pointing the array somewhere else anyway.</li>
 *   <li>You should NOT call <code>yylex()</code> on the generated scanner
 *       directly; rather, you should use <code>getTokenList</code> as you would
 *       with any other <code>TokenMaker</code> instance.</li>
 * </ul>
 *
 * @author Miguel Calejo / Robert Futrell
 * @version 0.1
 *
 */
@SuppressWarnings("unused")
%%

%public
%class FloraTokenMaker
%extends AbstractJFlexTokenMaker
%unicode
%type org.fife.ui.rsyntaxtextarea.Token


%{

	public static final int FULL_STOP = PrologTokenMaker.FULL_STOP; // defining our tokens requires recompiling rsyntaxtextarea

	/** Marks all similar variables in same term; requires changing a couple of access qualifiers 
	in package org.fife.ui.rsyntaxtextarea */

	protected OccurrenceMarker createOccurrenceMarker() {
		return LogicProgramEditor.createOccurrenceMarker();
	}

	public boolean getMarkOccurrencesOfTokenType(int type) {
		return LogicProgramEditor.getMarkOccurrencesOfTokenType(type);
	}
	
	
	/**
	 * Constructor.  This must be here because JFlex does not generate a
	 * no-parameter constructor.
	 */
	public FloraTokenMaker() {
	}


	/**
	 * Adds the token specified to the current linked list of tokens.
	 *
	 * @param tokenType The token's type.
	 */
	protected void addToken(int tokenType) {
		addToken(zzStartRead, zzMarkedPos-1, tokenType);
	}

	/**
	 * Adds the token specified to the current linked list of tokens.
	 *
	 * @param tokenType The token's type.
	 * @see #addHyperlinkToken(int, int, int)
	 */
	protected void addToken(int start, int end, int tokenType) {
		int so = start + offsetShift;
		addToken(zzBuffer, start,end, tokenType, so, false);
	}

	/**
	 * Returns the text to place at the beginning and end of a
	 * line to "comment" it in a this programming language.
	 */
	public String[] getLineCommentStartAndEnd() {
		return new String[] { "//", null };
	}


	/**
	 * Returns the first token in the linked list of tokens generated
	 * from <code>text</code>.  This method must be implemented by
	 * subclasses so they can correctly implement syntax highlighting.
	 *
	 * @param text The text from which to get tokens.
	 * @param initialTokenType The token type we should start with.
	 * @param startOffset The offset into the document at which
	 *        <code>text</code> starts.
	 * @return The first <code>Token</code> in a linked list representing
	 *         the syntax highlighted text.
	 */
	public Token getTokenList(Segment text, int initialTokenType, int startOffset) {

		resetTokenList();
		this.offsetShift = -text.offset + startOffset;

		// Start off in the proper state.
		int state = Token.NULL;
		switch (initialTokenType) {
			case Token.COMMENT_MULTILINE:
				state = MLC;
				start = text.offset;
				break;
			case Token.COMMENT_DOCUMENTATION:
				state = DOCCOMMENT;
				start = text.offset;
				break;
			case Token.LITERAL_STRING_DOUBLE_QUOTE:
				state = MLS;
				start = text.offset;
				break;
			default:
				state = Token.NULL;
		}

		s = text;
		try {
			yyreset(zzReader);
			yybegin(state);
			return yylex();
		} catch (IOException ioe) {
			ioe.printStackTrace();
			return new TokenImpl();
		}

	}

	/**
	 * Refills the input buffer.
	 *
	 * @return      <code>true</code> if EOF was reached, otherwise
	 *              <code>false</code>.
	 * @exception   IOException  if any I/O-Error occurs.
	 */
	private boolean zzRefill() {
		return zzCurrentPos>=s.offset+s.count;
	}


	/**
	 * Resets the scanner to read from a new input stream.
	 * Does not close the old reader.
	 *
	 * All internal variables are reset, the old input stream 
	 * <b>cannot</b> be reused (internal buffer is discarded and lost).
	 * Lexical state is set to <tt>YY_INITIAL</tt>.
	 *
	 * @param reader   the new input stream 
	 */
	public final void yyreset(java.io.Reader reader) {
		// 's' has been updated.
		zzBuffer = s.array;
		/*
		 * We replaced the line below with the two below it because zzRefill
		 * no longer "refills" the buffer (since the way we do it, it's always
		 * "full" the first time through, since it points to the segment's
		 * array).  So, we assign zzEndRead here.
		 */
		//zzStartRead = zzEndRead = s.offset;
		zzStartRead = s.offset;
		zzEndRead = zzStartRead + s.count - 1;
		zzCurrentPos = zzMarkedPos = s.offset;
		zzLexicalState = YYINITIAL;
		zzReader = reader;
		zzAtBOL  = true;
		zzAtEOF  = false;
	}


%}

MLCBegin				= "/*"
MLCEnd					= "*/"
DocCommentBegin			= "/**"
StringEnd	= "\""
StringBegin 	= "\""

LineTerminator = (\r|\n|\r\n)
WhiteSpace     = {LineTerminator} | [ \t\f]
StringText     = (\\\"|[^\n\"]|\\{WhiteSpace}+\\)*
String			= \"{StringText}\"

LiteralText	 = (''|\\\"|[^\n\"']|\\{WhiteSpace}+\\)*

Letter				= ([A-Za-z])
LetterOrUnderscore	= ({Letter}|"\_")
LetterOrUnderscoreOrDigit	= ({LetterOrUnderscore}|[0-9])

Digit							= ("0"|{NonzeroDigit})
NonzeroDigit						= ([1-9])

FloatHelper1				= ([fFdD]?)
FloatHelper2				= ([eE][+-]?{Digit}+{FloatHelper1})
/* Was causing problems with FULL_STOP :FloatLiteral1				= ({Digit}+"."({FloatHelper1}|{FloatHelper2}|{Digit}+({FloatHelper1}|{FloatHelper2})))*/
FloatLiteral1				= ({Digit}+"."({FloatHelper2}|{Digit}+({FloatHelper1}|{FloatHelper2})))
FloatLiteral2				= ("."{Digit}+({FloatHelper1}|{FloatHelper2}))
FloatLiteral3				= ({Digit}+{FloatHelper2})
FloatLiteral				= ({FloatLiteral1}|{FloatLiteral2}|{FloatLiteral3}|({Digit}+[fFdD]))

DigitOrUnderscore			= ({Digit}|[_])
DigitsAndUnderscoresEnd		= ({DigitOrUnderscore}*{Digit})
IntegerHelper				= (({NonzeroDigit}{DigitsAndUnderscoresEnd}?)|"0")
IntegerLiteral				= ({IntegerHelper}[lL]?)


/* Prolog-specific def's. */
Comma          = ","
Cut            = "!"
/* generate the following with: current_op(P,T,Name), write('"'), write(Name), write('"|'), fail. */
Operator        = ({Operator1}|{Operator2}|{Operator3}|{Operator4}|{Operator5})
Operator1	= (":-"|"-->"|":-"|"?-"|"::-"|"hilog"|"dynamic"|"multifile"|"meta_predicate"|"table"|"use_variant_tabling"|"use_subsumptive_tabling"|"use_incremental_tabling"|"use_incremental_dynamic"|"use_opaque_tabling"|"thread_shared"|"thread_private"|"edb"|"index"|"ti"|"ti_off")
Operator2 	= ("mode"|"document_export"|"export"|"parallel"|"local"|"foreign_pred"|"private_foreign_pred"|"compile_command"|"attribute"|"import"|"document_import"|"->"|","|"not"|"tnot"|"\+"|"spy"|"nospy"|"="|"\="|"=="|"@="|"\=="|"@<"|"@=<"|"@>"|"@>="|"=.."|"^=..")
Operator3		=( "=:="|"=\="|"<"|"=<"|">"|">="|"?=" /*|"."*/ |":"|"+"|"-"|"/\"|"\/"|"><"|"xor"|"+"|"-"|"\"|"*"|"/"|"//"|"mod"|"rem"|"div"|"<<"|">>"|"\\"|"**"|"\^"|"@_"|"\_@"|"@"|"\~"|"#"|"..")
Operator4	= ("while"|"loop"|"do"|"unless"|"if"|"function"|"udf"|"export")
Operator5	= ("\\isatomic" |"\\islist" | \\plg" |"\\prolog" |"\\prologall" | "\\isvar" | "\\isnonvar" |"\\naf" | "\\neg" | "\\is" | "\\if" | "\\then" | "\\else" | "\\while" | "\\do" | "\\unless" | "\\loop" | "\\until" | "\\udf" | "\\true" | "\\false" | "\\undefined" | "\\abolishtables" | "\\isa" | "\\memberof" | "\\sub" | "\\subclassof" | "\\hasvalue" | "\\hastype")
SpecialOperator	= (";"|"\\or"|"\\and")
Punctuation    = "(" | ")" | "\[" | "\]" | "\{" | "|" | "\}" | "\${" | "\[|"| "|\]"
Solo           = "`"

Variable       = "?"([_a-zA-Z][_a-zA-Z0-9]*)?
Constant	= ([\_a-zA-Z\%]{LetterOrUnderscoreOrDigit}*) | \'{LiteralText}\'

%state MLC
%state MLS
%state EOL_COMMENT
%state DOCCOMMENT

%%

/* Normal text. */
<YYINITIAL> {
	"/**/" { addToken(Token.COMMENT_MULTILINE); }  
	{DocCommentBegin}	{ start = zzMarkedPos-3; yybegin(DOCCOMMENT); }
	{MLCBegin}	{ start = zzMarkedPos-2; yybegin(MLC); }
	"//"			{ start = zzMarkedPos-2; yybegin(EOL_COMMENT); }
	^"#"{WhiteSpace}*{Constant}.*	{addToken(Token.PREPROCESSOR);}
    
	"\"\""	{addToken(Token.LITERAL_STRING_DOUBLE_QUOTE);}
    {StringBegin}  { start = zzMarkedPos-1; yybegin(MLS); }
    /* {String} {addToken(Token.LITERAL_STRING_DOUBLE_QUOTE); } */
    
    {FloatLiteral} 	{addToken(Token.LITERAL_NUMBER_FLOAT); }
	{IntegerLiteral}	{ addToken(Token.LITERAL_NUMBER_DECIMAL_INT); }
    {Comma} 	{addToken(Token.SEPARATOR);}
    /* (\.\n)   	{addToken(FULL_STOP);} 
    \.  /  [ \t]  	{addToken(FULL_STOP);}  WHY is \n not working...???? neither is $ 
    \.({WhiteSpace}|[#/]) 	{addToken(FULL_STOP); addToken(Token.WHITESPACE); } 
    "\.$"  	{addToken(FULL_STOP);} 
    (\.)$	{addToken(FULL_STOP);} 
    "\."{WhiteSpace}   	{addToken(FULL_STOP);} */

    /* OK..    "."{WhiteSpace}   	{addToken(FULL_STOP);  } */
    /* OK..."."  /  [ \t\n]  	{addToken(FULL_STOP);}  */ 
    
    "."  /  [^ \t\n]  	{addToken(Token.RESERVED_WORD);}
    /* The following follows the previous so we do not miss the last dot in file: */
    "."    	{addToken(FULL_STOP);}
    "@@{defeasible}"|"@@{strict}"	{addToken(Token.ANNOTATION); }
    @\{({Constant}|{String})*\}	{addToken(Token.ANNOTATION); }
    @\!\{({Constant}|{String})*\}	{addToken(Token.ANNOTATION); }
    /* @\!\{[^\}]\}	{addToken(Token.ANNOTATION); } */
    @\!{Constant}	{addToken(Token.ANNOTATION); } /* Should accept a term and not just a "constant" */
    {Operator} {addToken(Token.RESERVED_WORD);}
    {SpecialOperator} {addToken(Token.RESERVED_WORD_2);}
    {Punctuation} {addToken(Token.SEPARATOR);}
    {Cut} {addToken(Token.RESERVED_WORD); }
    {Solo} {addToken(Token.RESERVED_WORD);}
    {Variable} {addToken(Token.VARIABLE);}
    {Constant} 	{addToken(Token.IDENTIFIER); }
    {WhiteSpace}+ {addToken(Token.WHITESPACE); }
	/* Ended with a line not in a string or comment. */
	<<EOF>>						{ addNullToken(); return firstToken; }
	/* Catch any other (unhandled) characters and flag them as identifiers. */
	.	{ addToken(Token.ERROR_IDENTIFIER); }
}
<MLS> {
	[^hwf\n\"]+				{}
	[hwf]					{}
	\n						{ addToken(start,zzStartRead-1, Token.LITERAL_STRING_DOUBLE_QUOTE); return firstToken; }
	{StringEnd}					{ yybegin(YYINITIAL); addToken(start,zzStartRead, Token.LITERAL_STRING_DOUBLE_QUOTE); }
	<<EOF>>					{ addToken(start,zzStartRead-1, Token.LITERAL_STRING_DOUBLE_QUOTE); return firstToken; }
}
<MLC> {
	[^hwf\n\*]+				{}
	[hwf]					{}

	\n						{ addToken(start,zzStartRead-1, Token.COMMENT_MULTILINE); return firstToken; }
	{MLCEnd}					{ yybegin(YYINITIAL); addToken(start,zzStartRead+1, Token.COMMENT_MULTILINE); }
	\*						{}
	<<EOF>>					{ addToken(start,zzStartRead-1, Token.COMMENT_MULTILINE); return firstToken; }
}
<DOCCOMMENT> {
	[^hwf\n\*]+				{}
	[hwf]						{}

	\n							{ addToken(start,zzStartRead-1, Token.COMMENT_DOCUMENTATION); return firstToken; }
	{MLCEnd}					{ yybegin(YYINITIAL); addToken(start,zzStartRead+1, Token.COMMENT_DOCUMENTATION); }
	\*							{}
	<<EOF>>						{ yybegin(YYINITIAL); addToken(start,zzEndRead, Token.COMMENT_DOCUMENTATION); return firstToken; }
}
<EOL_COMMENT> {
	[^hwf\n]+				{}
	[hwf]					{}
	\n						{ addToken(start,zzStartRead-1, Token.COMMENT_EOL); addNullToken(); return firstToken; }
	<<EOF>>					{ addToken(start,zzStartRead-1, Token.COMMENT_EOL); addNullToken(); return firstToken; }
}

